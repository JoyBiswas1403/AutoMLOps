# ğŸš€ AutoMLOps â€” End-to-End MLOps Pipeline (MLflow + TF-Serving + Drift Detection + FastAPI)

[![Docker Compose](https://img.shields.io/badge/Docker--Compose-Ready-brightgreen?style=flat-square)](#)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking%20%26%20Registry-orange?style=flat-square)](#)
[![TensorFlow Serving](https://img.shields.io/badge/TF--Serving-Production%20Models-blue?style=flat-square)](#)
[![FastAPI](https://img.shields.io/badge/FastAPI-High%20Performance-009688?style=flat-square)](#)
[![MLOps](https://img.shields.io/badge/MLOps-End--to--End-purple?style=flat-square)](#)

> **A fully modular, end-to-end Machine Learning Operations (MLOps) system featuring MLflow tracking, TensorFlow Serving deployment, FastAPI inference API, data-drift detection, automated retraining, and production-style orchestration â€” all runnable with a single `docker compose up`.**

This project demonstrates **real MLOps engineering** â€” the same workflow used at companies like Google, Uber, and Netflix to train, deploy, monitor, and retrain ML models at scale.

---

# ğŸ¥ Demo (GIF / Video Placeholder)
> *(Replace with your GIF once recorded)*  
![demo-placeholder](docs/demo.gif)

---

# ğŸ§  Architecture Overview

```mermaid
flowchart TB
    subgraph DATA[Data Layer]
        data_gen[Data Generator] --> preprocess[Preprocessing]
    end

    subgraph TRAIN[Training Pipeline]
        preprocess --> trainer[Trainer]
        trainer --> mlflow[MLflow Tracking]
        trainer --> export_model[Model Export (SavedModel)]
    end

    subgraph DEPLOY[Deployment]
        export_model --> tfserving[TensorFlow Serving]
        tfserving --> api[FastAPI Inference API]
    end

    subgraph MONITOR[Monitoring & Retraining]
        api --> prometheus[Prometheus Metrics]
        prometheus --> grafana[Grafana Dashboard]
        preprocess --> drift[Data Drift Detector]
        drift -->|Drift Found| trainer
    end

    api --> users[Users / Applications]
    mlflow --> mlflow_ui[MLflow UI]
```


---

# âœ¨ Key Features

### âœ… 1. MLflow Tracking & Model Registry
- Automatic experiment logging  
- Versioned models stored in MLflow  
- Supports model promotion (Canary â†’ Production)

### âœ… 2. TensorFlow Serving Deployment
- Saves model as TF SavedModel  
- High-throughput serving  
- Standardized inference interface

### âœ… 3. FastAPI Inference Service
- Clean `/predict` endpoint  
- Input validation  
- Consistent preprocessing with persisted scalers

### âœ… 4. Data Drift Detection
- KS-test & PSI implementation  
- `--simulate` mode for testing  
- Automatic retraining trigger

### âœ… 5. Automated Retraining Pipeline
- Detect drift â†’ retrain â†’ register new model â†’ promote â†’ restart TF-Serving  
- Full MLOps lifecycle

### âœ… 6. Observability Stack
- Prometheus â†’ latency, throughput, error rates  
- Grafana â†’ dashboards & drift visualization

### âœ… 7. Fully Containerized
- Docker + Docker Compose  
- Zero manual environment setup  
- Reproducible pipeline

---

# âš¡ Quickstart (2 Minutes)

### 1ï¸âƒ£ Clone repo & setup env  
```bash
git clone https://github.com/JoyBiswas1403/AutoMLOps.git
cd AutoMLOps
cp .env.example .env
```

### 2ï¸âƒ£ Spin up the entire MLOps stack  
```bash
docker compose up -d --build
```

Services launched:
- MLflow â†’ http://localhost:5000  
- FastAPI â†’ http://localhost:8000/docs  
- TensorFlow Serving â†’ http://localhost:8501  
- Prometheus â†’ http://localhost:9090  
- Grafana â†’ http://localhost:3000  

### 3ï¸âƒ£ Train a new model  
```bash
docker compose run --rm trainer python -m training.src.train
```

### 4ï¸âƒ£ Promote canary â†’ production  
```bash
docker compose run --rm -e PYTHONPATH=/app trainer python pipelines/promote_canary.py
docker compose restart tfserving
```

### 5ï¸âƒ£ Make an inference request  
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"instances":[[0.1, 0.2, -1.3, ...]]}'
```

### 6ï¸âƒ£ Simulate data drift  
```bash
docker compose run --rm monitor python drift/detect_drift.py --simulate
```

---

# ğŸ“Š Results (Example â€” Replace With Real Values)

| Model Version | Test AUC | Drift Detected | Notes |
|---------------|----------|----------------|--------|
| v1 (baseline) | 0.78     | â€”              | Initial training |
| v2 (retrained) | 0.84     | Yes            | Auto-retrain triggered |

**Latency:** ~35 ms  
**Throughput:** ~300 req/s  

---

# ğŸ§¾ Model Card (Auto-Generated Template)

```
# Model Card â€” AutoMLOps

**Model Name:** TabularClassifier  
**Version:** vX  
**Created On:** YYYY-MM-DD  
**Framework:** TensorFlow (SavedModel)

## Overview
Binary classifier trained on synthetic/generated dataset.

## Metrics
AUC:  
Accuracy:  
Precision / Recall:

## Intended Use
Demo for MLOps lifecycle, CI/CD, retraining, drift detection.

## Limitations
Synthetic data; not intended for real-world clinical/financial use.

## Ethical Considerations
Validate with real data + domain experts.
```

---

# ğŸ–¼ï¸ Screenshots (Add these once ready)

### MLflow Tracking UI  
*(Insert screenshot here)*

### Grafana Dashboard  
*(Insert screenshot here)*

### FastAPI Docs  
*(Insert screenshot here)*

---

# ğŸ§© Project Structure

```
AutoMLOps/
â”‚â”€â”€ drift/
â”‚â”€â”€ grafana/
â”‚â”€â”€ mlflow/
â”‚â”€â”€ pipelines/
â”‚â”€â”€ prometheus/
â”‚â”€â”€ serving/
â”‚â”€â”€ training/
â”‚â”€â”€ .github/workflows/ci.yml
â”‚â”€â”€ docker-compose.yml
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
```

---

# ğŸš€ Roadmap
- [ ] Add demo GIF & screenshots  
- [ ] Add Evidently AI dashboards  
- [ ] Add canary traffic splitting (Nginx / router)  
- [ ] Add more unit tests + integration tests in CI  
- [ ] Add Data Versioning (DVC / LakeFS)  
- [ ] Deploy API to cloud (Render/AWS/GCP)

---

# ğŸ¤ Contributing
PRs, issues, and suggestions are welcome â€” this project is designed to evolve into a complete MLOps reference system.

---

# ğŸ“„ License
MIT License  
